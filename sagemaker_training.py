import argparse
import os
import json
import pickle
import numpy as np
import pandas as pd
import glob
from datetime import datetime
import logging
from stable_baselines3 import SAC
from stable_baselines3.common.evaluation import evaluate_policy
from stable_baselines3.common.callbacks import BaseCallback
import gymnasium as gym
from gymnasium import spaces
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# shimmy ì„í¬íŠ¸
try:
    import shimmy
    SHIMMY_AVAILABLE = True
except ImportError:
    SHIMMY_AVAILABLE = False
    print("shimmyê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - pip install shimmy ì‹¤í–‰ í•„ìš”")
    

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PerformanceMetricsCallback(BaseCallback):
    """ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¶”ì """
    
    def __init__(self, eval_env, eval_freq=2000, verbose=0):
        super(PerformanceMetricsCallback, self).__init__(verbose)
        self.eval_env = eval_env
        self.eval_freq = eval_freq
        self.metrics_history = {
            'episode': [],
            'timestep': [],
            'energy_efficiency': [],
            'soc_decrease_rate': [],
            'speed_tracking_rate': [],
            'target_speed_proximity': [],
            'comfort_score': [],
            'safety_violations': [],
            'convergence_reward': [],
            'learning_stability': []
        }
        self.episode_rewards = []
        self.last_episode_count = 0
    
    def _on_step(self) -> bool:
        if self.n_calls % self.eval_freq == 0:
            try:
                # í™˜ê²½ì´ ë²¡í„°í™”ëœ í™˜ê²½ì¸ì§€ í™•ì¸
                if hasattr(self.training_env, 'get_attr'):
                    # ë²¡í„°í™”ëœ í™˜ê²½ì˜ ê²½ìš°
                    current_metrics_list = self.training_env.get_attr('get_current_metrics')
                    episode_counts = self.training_env.get_attr('episode_count')
                    
                    # ì²« ë²ˆì§¸ í™˜ê²½ì˜ ë©”íŠ¸ë¦­ ì‚¬ìš©
                    if current_metrics_list and episode_counts:
                        current_metrics = current_metrics_list[0]() if callable(current_metrics_list[0]) else current_metrics_list[0]
                        current_episode = episode_counts[0]
                    else:
                        current_metrics = {'energy_efficiency': 4.0}
                        current_episode = 0
                        
                else:
                    # ë‹¨ì¼ í™˜ê²½ì˜ ê²½ìš°
                    if hasattr(self.training_env, 'get_current_metrics'):
                        current_metrics = self.training_env.get_current_metrics()
                    else:
                        current_metrics = {'energy_efficiency': 4.0}
                    
                    if hasattr(self.training_env, 'episode_count'):
                        current_episode = self.training_env.episode_count
                    else:
                        current_episode = 0
                
                # ì‹¤ì œ íš¨ìœ¨ê°’ ë¡œê·¸ ì¶œë ¥
                efficiency = current_metrics.get('energy_efficiency', 4.0)
                logger.info(f"Step {self.n_calls}: Energy Efficiency = {efficiency:.3f} km/kWh")
                
                # ìƒˆ ì—í”¼ì†Œë“œ ì™„ë£Œì‹œë§Œ ê¸°ë¡
                if current_episode > self.last_episode_count:
                    self.last_episode_count = current_episode
                    
                    self.metrics_history['timestep'].append(self.n_calls)
                    self.metrics_history['episode'].append(current_episode)
                    self.metrics_history['energy_efficiency'].append(efficiency)
                    self.metrics_history['soc_decrease_rate'].append(
                        current_metrics.get('soc_decrease_rate', 15.0)
                    )
                    self.metrics_history['speed_tracking_rate'].append(
                        current_metrics.get('speed_tracking_rate', 85.0)
                    )
                    
            except Exception as e:
                logger.warning(f"Metrics collection failed at step {self.n_calls}: {e}")
                
        return True


class EVEnergyEnvironmentPreprocessed(gym.Env):
    """ì „ì²˜ë¦¬ëœ ë°ì´í„° í™œìš© ì „ê¸°ì°¨ ì—ë„ˆì§€ íš¨ìœ¨ ìµœì í™” í™˜ê²½"""
    
    def __init__(self, data_dir, config=None):
        super(EVEnergyEnvironmentPreprocessed, self).__init__()
        
        # í™˜ê²½ ì„¤ì •
        self.data_dir = data_dir
        self.config = config or {}
        
        # ìƒíƒœ ê³µê°„: 28ì°¨ì› (í™•ì¸ë¨)
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, shape=(28,), dtype=np.float32
        )
        
        # í–‰ë™ ê³µê°„: ê°€ì†ë„ [-3.0, 3.0] m/sÂ²
        self.action_space = spaces.Box(
            low=-3.0, high=3.0, shape=(1,), dtype=np.float32
        )
        
        # ì•„ì´ì˜¤ë‹‰5 ì°¨ëŸ‰ ì œì› (ì‹¤ì œ ìŠ¤í™)
        self.vehicle_specs = {
            'mass': 2050,  # kg
            'battery_capacity': 77.4,  # kWh
            'motor_max_torque': 350,  # Nm
            'drag_coefficient': 0.28,
            'frontal_area': 2.8,  # mÂ²
            'wheel_radius': 0.35,  # m
            'final_drive_ratio': 7.4,
            'motor_efficiency': 0.95,
            'battery_efficiency': 0.95,
            'regen_efficiency': 0.80
        }
        
        # ë„ë¡œ ì €í•­ ê³„ìˆ˜ (ë…¼ë¬¸ Table 1 ê¸°ì¤€)
        self.road_resistance = {
            'f0': 53.90,  # N
            'f1': 0.21,   # Nâ‹…s/m
            'f2': 0.02    # Nâ‹…sÂ²/mÂ²
        }
        
        # ì„±ëŠ¥ ì¶”ì  ë³€ìˆ˜
        self.episode_data = {
            'speeds': [],
            'accelerations': [],
            'energy_consumption': [],
            'soc_changes': [],
            'rewards': [],
            'rush_periods': [],
            'traffic_conditions': [],
            'distances': [],
            'elevation_changes': []
        }
        
        # í˜„ì¬ ìƒíƒœ
        self.current_data_idx = 0
        self.current_speed = 30.0  # km/h
        self.current_soc = 0.8
        self.step_count = 0
        self.total_distance = 0.0  # km
        self.total_energy_consumed = 0.0  # kWh
        
        # ëª©í‘œ ì†ë„ (í‰ì¼ ì„œìš¸ ë„ì‹¬ ì¶œí‡´ê·¼ í‰ê·  ì†ë„)
        self.target_speed = 30.0  # km/h
        
        # ì—í”¼ì†Œë“œ ì¹´ìš´í„°
        self.episode_count = 0
        
        self._load_preprocessed_data()
        self.reset()

    def get_current_metrics(self):
        """í˜„ì¬ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        # ì‹¤ì œ íš¨ìœ¨ ê³„ì‚° (í•™ìŠµ ì§„í–‰ í™•ì¸ ê°€ëŠ¥í•˜ë„ë¡ ìˆ˜ì •ë¨)
        energy_efficiency = self._calculate_current_efficiency()
        
        # SOC ê°ì†Œìœ¨
        initial_soc = 0.8
        soc_decrease_rate = ((initial_soc - self.current_soc) / initial_soc) * 100
        
        # ì†ë„ ì¶”ì¢…ë¥ 
        if len(self.episode_data['speeds']) > 0:
            speeds = np.array(self.episode_data['speeds'])
            in_range = np.abs(speeds - self.target_speed) <= 5
            speed_tracking_rate = np.mean(in_range) * 100
            target_speed_proximity = np.mean(np.abs(speeds - self.target_speed))
        else:
            speed_tracking_rate = max(0, 100 - abs(self.current_speed - self.target_speed) * 5)
            target_speed_proximity = abs(self.current_speed - self.target_speed)
        
        return {
            'energy_efficiency': energy_efficiency,
            'soc_decrease_rate': soc_decrease_rate,
            'speed_tracking_rate': speed_tracking_rate,
            'target_speed_proximity': target_speed_proximity,
            'total_distance': self.total_distance,
            'total_energy_consumed': self.total_energy_consumed
        }

    def _parse_state_vector(self, vector_str):
        """ìƒíƒœ ë²¡í„° ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ - ê²¬ê³ í•˜ê²Œ ìˆ˜ì •"""
        try:
            if isinstance(vector_str, str):
                # ë”°ì˜´í‘œ ì œê±°
                clean_str = vector_str.strip('"\'')
                # ëŒ€ê´„í˜¸ ë‚´ë¶€ ì¶”ì¶œ
                if '[' in clean_str and ']' in clean_str:
                    start = clean_str.find('[')
                    end = clean_str.find(']') + 1
                    vector_part = clean_str[start:end]
                    # ëŒ€ê´„í˜¸ ì œê±°í•˜ê³  íŒŒì‹±
                    content = vector_part.strip('[]')
                    return [float(x.strip()) for x in content.split(',')]
                else:
                    # ëŒ€ê´„í˜¸ ì—†ì´ ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê²½ìš°
                    return [float(x.strip()) for x in clean_str.split(',')]
            elif isinstance(vector_str, list):
                return vector_str
            else:
                logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ ë²¡í„° í˜•ì‹: {type(vector_str)}")
                return [0.0] * 28
        except Exception as e:
            logger.warning(f"ìƒíƒœ ë²¡í„° íŒŒì‹± ì˜¤ë¥˜: {e}")
            return [0.0] * 28

    def _get_default_normalization(self):
        """ê¸°ë³¸ ì •ê·œí™” ë²”ìœ„"""
        return {
            'morning_rush': {'traffic_volume': {'min': 1446, 'max': 1764}},
            'evening_rush': {'traffic_volume': {'min': 1896, 'max': 2130}},
            'weather': {
                'temperature': {'min': -17.2, 'max': 35.8},
                'humidity': {'min': 15.0, 'max': 100.0},
                'wind_speed': {'min': 0.0, 'max': 8.1},
                'precipitation': {'min': 0.0, 'max': 34.7}
            }
        }
    
    def _load_preprocessed_data(self):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ - SageMaker ê²½ë¡œ ìµœì í™”"""
        try:
            # SageMaker í™˜ê²½ì—ì„œì˜ ë°ì´í„° ê²½ë¡œ
            train_patterns = [
                f"{self.data_dir}/train_statistically_valid_*.csv",
                f"{self.data_dir}/train_statistically_valid_*.csv", 
                f"{self.data_dir}/*train*.csv",
                f"{self.data_dir}/*.csv"
            ]
            
            test_patterns = [
                f"{self.data_dir}/test_statistically_valid_*.csv",
                f"{self.data_dir}/test_statistically_valid_*.csv",
                f"{self.data_dir}/*test*.csv"
            ]
            
            norm_patterns = [
                f"{self.data_dir}/rush_normalization_corrected_*.json",
                f"{self.data_dir}/rush_normalization*.json"
            ]
            
            # í›ˆë ¨ ë°ì´í„° ì°¾ê¸°
            train_files = []
            for pattern in train_patterns:
                files = glob.glob(pattern)
                if files:
                    train_files = files
                    logger.info(f"í›ˆë ¨ ë°ì´í„° ë°œê²¬: {pattern}")
                    break
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì°¾ê¸°  
            test_files = []
            for pattern in test_patterns:
                files = glob.glob(pattern)
                if files:
                    test_files = files
                    logger.info(f" í…ŒìŠ¤íŠ¸ ë°ì´í„° ë°œê²¬: {pattern}")
                    break
                    
            # ì •ê·œí™” íŒŒì¼ ì°¾ê¸°
            norm_files = []
            for pattern in norm_patterns:
                files = glob.glob(pattern)
                if files:
                    norm_files = files
                    logger.info(f" ì •ê·œí™” ë°ì´í„° ë°œê²¬: {pattern}")
                    break
            
            if train_files:
                self.train_data = pd.read_csv(train_files[0])
                logger.info(f" í›ˆë ¨ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.train_data)}í–‰ Ã— {len(self.train_data.columns)}ì—´")
                
                if 'state_vector_rush' in self.train_data.columns:
                    logger.info(" state_vector_rush ì»¬ëŸ¼ ì¡´ì¬ - íŒŒì‹± ì‹œì‘")
                    self.train_data['state_vector_rush'] = self.train_data['state_vector_rush'].apply(
                        self._parse_state_vector
                    )
                    
                    # ì°¨ì› ê²€ì¦
                    sample_state = self.train_data['state_vector_rush'].iloc[0]
                    actual_dim = len(sample_state)
                    logger.info(f" ìƒíƒœ ë²¡í„° ì°¨ì› í™•ì¸: {actual_dim}ì°¨ì›")
                    
                    if actual_dim != 28:
                        logger.warning(f" ì˜ˆìƒ ì°¨ì›(28)ê³¼ ì‹¤ì œ ì°¨ì›({actual_dim})ì´ ë‹¤ë¦„")
                        # ê´€ì°° ê³µê°„ ë™ì  ì¡°ì •
                        self.observation_space = spaces.Box(
                            low=-np.inf, high=np.inf, shape=(actual_dim,), dtype=np.float32
                        )
                    
                    logger.info(" state_vector_rush íŒŒì‹± ì™„ë£Œ")
                else:
                    logger.warning("state_vector_rush ì»¬ëŸ¼ì´ ì—†ìŒ, ê¸°ë³¸ ìƒíƒœë²¡í„° ìƒì„±")
                    self._create_basic_state_vectors()
                
            else:
                logger.error(" í›ˆë ¨ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                self._create_dummy_data()
                return
            
            if test_files:
                self.test_data = pd.read_csv(test_files[0])
                logger.info(f" í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.test_data)}í–‰")
                
                if 'state_vector_rush' in self.test_data.columns:
                    self.test_data['state_vector_rush'] = self.test_data['state_vector_rush'].apply(
                        self._parse_state_vector
                    )
            
            # ì •ê·œí™” ë²”ìœ„ ë¡œë“œ
            if norm_files:
                with open(norm_files[0], 'r') as f:
                    self.normalization_ranges = json.load(f)
                logger.info(" ì •ê·œí™” ë²”ìœ„ ë¡œë“œ ì™„ë£Œ")
            else:
                self.normalization_ranges = self._get_default_normalization()
                logger.info("ê¸°ë³¸ ì •ê·œí™” ë²”ìœ„ ì‚¬ìš©")
                
            # ë°ì´í„° ìš”ì•½ ì¶œë ¥
            logger.info("=" * 50)
            logger.info("ë°ì´í„° ë¡œë“œ ì™„ë£Œ ìš”ì•½:")
            logger.info(f"  í›ˆë ¨ ë°ì´í„°: {len(self.train_data) if hasattr(self, 'train_data') else 0}í–‰")
            logger.info(f"  í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(self.test_data) if hasattr(self, 'test_data') else 0}í–‰")
            logger.info(f"  ì£¼ìš” ì»¬ëŸ¼: {list(self.train_data.columns)[:10] if hasattr(self, 'train_data') else 'None'}...")
            logger.info("=" * 50)
                
        except Exception as e:
            logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            self._create_dummy_data()
    
    def _create_basic_state_vectors(self):
        """ê¸°ë³¸ ìƒíƒœ ë²¡í„° ìƒì„±"""
        logger.info("ê¸°ë³¸ ìƒíƒœ ë²¡í„° ìƒì„± ì¤‘...")
        
        def create_state_vector(row):
            return [
                np.random.uniform(0, 1),  # ì‹œê°„
                np.random.uniform(0, 1),  # ì›”
                np.random.uniform(0, 1),  # êµí†µëŸ‰
                np.random.uniform(-1, 1), np.random.uniform(-1, 1),  # ì‹œê°„ ì£¼ê¸°ì„±
                np.random.uniform(-1, 1), np.random.uniform(-1, 1),  # ì›” ì£¼ê¸°ì„±
                np.random.randint(0, 2), np.random.randint(0, 2),     # ë°©í–¥
                0, 0, 1,  # ë”ë¯¸
                np.random.randint(0, 2), np.random.randint(0, 2),     # ì¶œí‡´ê·¼
                np.random.randint(0, 2), np.random.randint(0, 2),     # ì‹œê°„ëŒ€
                np.random.uniform(0, 1),  # ì˜¨ë„
                np.random.uniform(0, 1),  # ìŠµë„
                np.random.uniform(0, 1),  # í’ì†
                np.random.uniform(0, 1),  # ê°•ìˆ˜ëŸ‰
                np.random.uniform(-0.1, 0.1),  # ê²½ì‚¬ë„
                1,  # visibility
                np.random.randint(0, 2),  # ê°•ìˆ˜ ì—¬ë¶€
                1.0,  # difficulty
                np.random.randint(0, 2), np.random.randint(0, 2),  # ì¶œí‡´ê·¼ ì„¸ë¶€
                0.8,  # SOC
                0.5,  # ì†ë„
                0.0   # ì¶”ê°€
            ]
        
        self.train_data['state_vector_rush'] = [create_state_vector(None) for _ in range(len(self.train_data))]
    
    def _create_dummy_data(self):
        """ë”ë¯¸ ë°ì´í„° ìƒì„±"""
        logger.info("ë”ë¯¸ ë°ì´í„° ìƒì„± ì¤‘...")
        
        dummy_data = []
        for i in range(1000):
            state_vector = [np.random.uniform(-1, 1) for _ in range(28)]
            
            dummy_data.append({
                'state_vector_rush': state_vector,
                'rush_separated_reward': np.random.uniform(0.3, 0.9),
                'rush_period_detailed': np.random.choice(['morning_rush', 'evening_rush']),
                'traffic_volume': np.random.uniform(1000, 2000),
                'hour': np.random.randint(7, 21),
                'month': np.random.randint(1, 13),
                'temperature': np.random.uniform(-5, 30),
                'road_avg_gradient': np.random.uniform(-0.05, 0.05)
            })
        
        self.train_data = pd.DataFrame(dummy_data)
    
    def step(self, action):
        acceleration = action[0]
        
        # í˜„ì¬ ë°ì´í„° í–‰ ê°€ì ¸ì˜¤ê¸°
        if self.current_data_idx < len(self.train_data):
            current_row = self.train_data.iloc[self.current_data_idx]
        else:
            current_row = self.train_data.sample(1).iloc[0]
        
        # ë¬¼ë¦¬ ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜
        old_speed_kmh = self.current_speed
        old_speed_ms = old_speed_kmh / 3.6
        
        # ê°€ì†ë„ ì ìš© (dt = 1ì´ˆ)
        new_speed_ms = max(0, old_speed_ms + acceleration * 1.0)
        new_speed_kmh = new_speed_ms * 3.6
        
        # ì´ë™ ê±°ë¦¬ ê³„ì‚°
        avg_speed_ms = (old_speed_ms + new_speed_ms) / 2
        distance_step = avg_speed_ms * 1.0 / 1000  # km
        self.total_distance += distance_step
        
        # ì—ë„ˆì§€ ì†Œë¹„ ê³„ì‚°
        energy_consumption = self._calculate_energy_consumption(old_speed_ms, new_speed_ms, acceleration)
        
        # SOC ì—…ë°ì´íŠ¸
        soc_decrease = energy_consumption / self.vehicle_specs['battery_capacity']
        new_soc = max(0, self.current_soc - soc_decrease)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self.current_speed = new_speed_kmh
        self.current_soc = new_soc
        self.total_energy_consumed += energy_consumption
        
        # ì—í”¼ì†Œë“œ ë°ì´í„° ìˆ˜ì§‘
        self.episode_data['speeds'].append(new_speed_kmh)
        self.episode_data['accelerations'].append(acceleration)
        self.episode_data['energy_consumption'].append(energy_consumption)
        self.episode_data['soc_changes'].append(soc_decrease)
        
        # ìƒíƒœ ë²¡í„° ì„¤ì •
        if isinstance(current_row['state_vector_rush'], list):
            self.state = np.array(current_row['state_vector_rush'], dtype=np.float32)
        else:
            self.state = np.random.uniform(-1, 1, 28).astype(np.float32)
        
        # ë™ì  ìš”ì†Œ ì—…ë°ì´íŠ¸
        if len(self.state) >= 28:
            self.state[25] = new_soc  # SOC ì—…ë°ì´íŠ¸
            self.state[26] = new_speed_kmh / 120.0  # ì†ë„ ì •ê·œí™”
        
        # ë³´ìƒ ê³„ì‚°
        reward = self._calculate_reward(acceleration, energy_consumption, new_speed_kmh, new_soc)
        self.episode_data['rewards'].append(reward)
        
        # ì¢…ë£Œ ì¡°ê±´
        self.step_count += 1
        self.current_data_idx += 1
        
        terminated = self.total_distance >= 7.816 or new_soc <= 0.05 or self.step_count >= 500
        truncated = False
        
        info = {
            'current_speed': self.current_speed,
            'current_soc': self.current_soc,
            'energy_efficiency': self._calculate_current_efficiency(),
            'step_count': self.step_count,
            'total_distance': self.total_distance,
            'total_energy_consumed': self.total_energy_consumed
        }
        
        return self.state.copy(), reward, terminated, truncated, info
    
    def _calculate_energy_consumption(self, old_speed_ms, new_speed_ms, acceleration):
        """ì—ë„ˆì§€ ì†Œë¹„ ê³„ì‚°"""
        g = 9.81
        air_density = 1.225
        avg_speed_ms = (old_speed_ms + new_speed_ms) / 2
        
        # ì €í•­ë ¥ ê³„ì‚°
        rolling_resistance = (self.road_resistance['f0'] + 
                            self.road_resistance['f1'] * avg_speed_ms + 
                            self.road_resistance['f2'] * avg_speed_ms**2)
        
        drag_force = 0.5 * air_density * self.vehicle_specs['drag_coefficient'] * \
                    self.vehicle_specs['frontal_area'] * avg_speed_ms**2
        
        inertial_force = self.vehicle_specs['mass'] * acceleration
        
        total_force = rolling_resistance + drag_force + inertial_force
        power_required = total_force * avg_speed_ms
        
        # íšŒìƒ ì œë™ ê³ ë ¤
        if power_required < 0 and new_speed_ms > 5:
            power_required *= -self.vehicle_specs['regen_efficiency']
        
        # íš¨ìœ¨ ì ìš©
        if power_required > 0:
            battery_power = power_required / (self.vehicle_specs['motor_efficiency'] * 
                                            self.vehicle_specs['battery_efficiency'])
        else:
            battery_power = power_required * self.vehicle_specs['regen_efficiency']
        
        energy_consumption = abs(battery_power) / 3600000  # kWh
        return max(0.0001, energy_consumption)
    
    def _calculate_reward(self, acceleration, energy_consumption, speed, soc):
        """ë³´ìƒ í•¨ìˆ˜"""
        # ì—ë„ˆì§€ íš¨ìœ¨ì„± ë³´ìƒ
        current_efficiency = self._calculate_current_efficiency()
        baseline_efficiency = 4.2
        efficiency_reward = (current_efficiency - baseline_efficiency) / baseline_efficiency * 0.6
        
        # ì†ë„ ì¶”ì¢… ë³´ìƒ
        speed_error = abs(speed - self.target_speed)
        speed_reward = max(0, (10 - speed_error) / 10) * 0.3
        
        # ì£¼í–‰ ì•ˆì „ì„±
        comfort_penalty = min(abs(acceleration) / 3.0, 1.0) * 0.1
        
        # SOC ê´€ë¦¬
        soc_penalty = 0.2 if soc < 0.2 else 0
        
        total_reward = 0.7 + efficiency_reward + speed_reward - comfort_penalty - soc_penalty
        return max(0.1, min(1.0, total_reward))
    
    def _calculate_current_efficiency(self):
        """í˜„ì¬ ì—ë„ˆì§€ íš¨ìœ¨ ê³„ì‚° - ê³ ì •ê°’ ë¬¸ì œ í•´ê²°ë¨"""
        if self.total_energy_consumed > 0.0001 and self.total_distance > 0.0001:
            efficiency = self.total_distance / self.total_energy_consumed
            # í•™ìŠµ ì§„í–‰ì„ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ë„“ì€ ë²”ìœ„ í—ˆìš©
            return max(0.1, min(50.0, efficiency))
        # ì´ˆê¸° ìƒíƒœì—ì„œëŠ” ë‚®ì€ ê°’ ë°˜í™˜ (í•™ìŠµ ì§„í–‰ í™•ì¸ ê°€ëŠ¥)
        return 1.0
    
    def get_episode_metrics(self):
        """ì—í”¼ì†Œë“œ ì¢…ë£Œ ì‹œ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"""
        if len(self.episode_data['speeds']) == 0:
            return {
                'energy_efficiency': self._calculate_current_efficiency(),
                'soc_decrease_rate': ((0.8 - self.current_soc) / 0.8) * 100,
                'speed_tracking_rate': max(0, 100 - abs(self.current_speed - self.target_speed) * 5),
                'target_speed_proximity': abs(self.current_speed - self.target_speed),
                'comfort_score': 7.0,
                'safety_violations': 0
            }
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        energy_efficiency = self._calculate_current_efficiency()
        
        initial_soc = 0.8
        soc_decrease_rate = ((initial_soc - self.current_soc) / initial_soc) * 100
        
        speeds = np.array(self.episode_data['speeds'])
        in_range = np.abs(speeds - self.target_speed) <= 5
        speed_tracking_rate = np.mean(in_range) * 100
        
        target_speed_proximity = np.mean(np.abs(speeds - self.target_speed))
        
        accelerations = np.array(self.episode_data['accelerations'])
        comfort_score = max(0, 10 - np.std(accelerations) * 5)
        
        safety_violations = np.sum(np.abs(accelerations) > 2.5)
        
        return {
            'energy_efficiency': energy_efficiency,
            'soc_decrease_rate': soc_decrease_rate,
            'speed_tracking_rate': speed_tracking_rate,
            'target_speed_proximity': target_speed_proximity,
            'comfort_score': comfort_score,
            'safety_violations': safety_violations
        }
    
    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
    
        # ì—í”¼ì†Œë“œ ì¹´ìš´í„° ì¦ê°€
        self.episode_count += 1
    
        # ì°¨ëŸ‰ ìƒíƒœ ì´ˆê¸°í™”
        self.current_data_idx = 0
        self.current_speed = 60.0
        self.current_soc = 0.8
        self.step_count = 0
        self.total_distance = 0.0
        self.total_energy_consumed = 0.0
    
        # ì—í”¼ì†Œë“œ ë°ì´í„° ì´ˆê¸°í™”
        self.episode_data = {
            'speeds': [],
            'accelerations': [],
            'energy_consumption': [],
            'soc_changes': [],
            'rewards': [],
            'rush_periods': [],
            'traffic_conditions': [],
            'distances': [],
            'elevation_changes': []
        }

        info = {
            'initial_soc': self.current_soc,
            'initial_speed': self.current_speed,
            'route_distance': 7.816
        }
    
        # ëœë¤ ë°ì´í„° ìƒ˜í”Œ ì„ íƒ
        if hasattr(self, 'train_data') and len(self.train_data) > 0:
            self.current_data_idx = np.random.randint(0, len(self.train_data))
            initial_row = self.train_data.iloc[self.current_data_idx]
        
            if isinstance(initial_row['state_vector_rush'], list):
                self.state = np.array(initial_row['state_vector_rush'], dtype=np.float32)
            else:
                self.state = np.random.uniform(-1, 1, 28).astype(np.float32)
        
            if len(self.state) >= 28:
                self.state[25] = self.current_soc
                self.state[26] = self.current_speed / 120.0
        else:
            self.state = np.random.uniform(-1, 1, 28).astype(np.float32)
    
        return self.state.copy(), info

# í¬ë£¨ì¦ˆ ëª¨ë“œ ê¸°ì¤€ì„ 
class CruiseControlBaseline:
    """í¬ë£¨ì¦ˆ ëª¨ë“œ ê¸°ì¤€ì„  - ì¼ì • ì†ë„ ìœ ì§€"""
    
    def __init__(self, target_speed=60.0):
        self.target_speed = target_speed
        self.kp = 0.8
        self.ki = 0.1
        self.kd = 0.05
        self.integral_error = 0
        self.previous_error = 0
    
    def predict(self, observation, deterministic=True):
        """PID ì œì–´ë¡œ ëª©í‘œ ì†ë„ ìœ ì§€"""
        current_speed_normalized = observation[26] if len(observation) > 26 else 0.5
        current_speed = current_speed_normalized * 120.0
        
        error = self.target_speed - current_speed
        
        self.integral_error += error
        derivative_error = error - self.previous_error
        
        acceleration = (self.kp * error + 
                       self.ki * self.integral_error + 
                       self.kd * derivative_error)
        
        acceleration = np.clip(acceleration, -3.0, 3.0)
        self.previous_error = error
        
        return np.array([acceleration]), None


def evaluate_cruise_baseline(env, num_episodes=50):
    """í¬ë£¨ì¦ˆ ëª¨ë“œ ê¸°ì¤€ì„  í‰ê°€ - SageMaker ì„¤ì •"""
    cruise_controller = CruiseControlBaseline(target_speed=60.0)
    
    episode_metrics = []
    episode_rewards = []
    
    for episode in range(num_episodes):
        obs, _ = env.reset()
        episode_reward = 0
        done = False
        
        while not done:
            action, _ = cruise_controller.predict(obs)
            obs, reward, terminated, truncated, info = env.step(action)
            episode_reward += reward
            done = terminated or truncated
        
        metrics = env.get_episode_metrics()
        episode_metrics.append(metrics)
        episode_rewards.append(episode_reward)
    
    # í‰ê·  ì„±ëŠ¥ ê³„ì‚°
    avg_efficiency = np.mean([m['energy_efficiency'] for m in episode_metrics])
    avg_speed_tracking = np.mean([m['speed_tracking_rate'] for m in episode_metrics])
    avg_reward = np.mean(episode_rewards)
    
    return {
        'energy_efficiency': {'mean': avg_efficiency, 'values': [m['energy_efficiency'] for m in episode_metrics]},
        'speed_tracking_rate': {'mean': avg_speed_tracking, 'values': [m['speed_tracking_rate'] for m in episode_metrics]},
        'episode_reward': {'mean': avg_reward, 'values': episode_rewards}
    }, episode_metrics


def install_transfer_learning_dependencies():
    """ì „ì´í•™ìŠµ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"""
    try:
        import subprocess
        import sys
        
        logger.info("ğŸ”§ ì „ì´í•™ìŠµ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘...")
        
        # huggingface_sb3 ì„¤ì¹˜
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", 
            "huggingface-sb3", "--quiet"
        ])
        
        logger.info(" huggingface_sb3 ì„¤ì¹˜ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.warning(f" ì „ì´í•™ìŠµ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì‹¤íŒ¨: {e}")
        return False


def train_sac_model(model_name, is_transfer_learning=False, total_timesteps=100000, data_dir="./data", save_dir="./models"):
    """SAC ëª¨ë¸ í›ˆë ¨ - SageMaker ìµœì í™”"""
    
    logger.info(f" SAC ëª¨ë¸ í›ˆë ¨ ì‹œì‘: {model_name}")
    logger.info(f"ì „ì´í•™ìŠµ: {is_transfer_learning}")
    logger.info(f" ì´ ìŠ¤í…: {total_timesteps}")
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(save_dir, exist_ok=True)
    os.makedirs("./results", exist_ok=True)
    
    # í™˜ê²½ ìƒì„±
    env = EVEnergyEnvironmentPreprocessed(data_dir=data_dir)
    
    # SageMaker ìµœì í™”ëœ SAC ì„¤ì •
    sac_config = {
        'learning_rate': 3e-4,
        'buffer_size': 100000,
        'batch_size': 256,  # ì‹¤í—˜ ì„¤ê³„ì„œ ê¶Œì¥ê°’
        'tau': 0.005,
        'gamma': 0.99,
        'train_freq': 1,
        'gradient_steps': 1,
        'verbose': 1,
        'device': 'cuda' if torch.cuda.is_available() else 'cpu'
    }
    
    # ëª¨ë¸ ìƒì„±
    if is_transfer_learning:
        logger.info(" ì „ì´í•™ìŠµ ëª¨ë¸ ë¡œë“œ ì‹œë„...")
        
        # ì „ì´í•™ìŠµ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
        if install_transfer_learning_dependencies():
            try:
                from huggingface_sb3 import load_from_hub
                
                # ì‚¬ì „í•™ìŠµ ëª¨ë¸ í›„ë³´ë“¤ (ì‹¤í—˜ ì„¤ê³„ì„œ ê¸°ì¤€)
                pretrained_models = [
                    ("sb3/sac-LunarLanderContinuous-v2", "sac-LunarLanderContinuous-v2.zip"),
                    ("sb3/sac-BipedalWalker-v3", "sac-BipedalWalker-v3.zip"),
                    ("sb3/sac-Pendulum-v1", "sac-Pendulum-v1.zip")
                ]
                
                model = None
                for repo_id, filename in pretrained_models:
                    try:
                        logger.info(f"ğŸ” {repo_id} ëª¨ë¸ ë¡œë“œ ì‹œë„...")
                        checkpoint = load_from_hub(repo_id=repo_id, filename=filename)
                        
                        # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ
                        temp_model = SAC.load(checkpoint)
                        
                        # ìƒˆ í™˜ê²½ì— ë§ê²Œ ëª¨ë¸ ì¬ìƒì„± (ë„¤íŠ¸ì›Œí¬ êµ¬ì¡° ë³µì‚¬)
                        model = SAC(
                            policy=temp_model.policy_class,
                            env=env,
                            **sac_config
                        )
                        
                        # ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ë³µì‚¬ (ì‹¤í—˜ ì„¤ê³„ì„œ ë„ë©”ì¸ ì ì‘ ì „ëµ)
                        try:
                            model.policy.load_state_dict(temp_model.policy.state_dict(), strict=False)
                            logger.info(f" {repo_id} ëª¨ë¸ì—ì„œ ì „ì´í•™ìŠµ ì„±ê³µ!")
                            break
                        except:
                            logger.warning(f" {repo_id} íŒŒë¼ë¯¸í„° ë³µì‚¬ ì‹¤íŒ¨, ë‹¤ìŒ ëª¨ë¸ ì‹œë„")
                            continue
                            
                    except Exception as e:
                        logger.warning(f" {repo_id} ë¡œë“œ ì‹¤íŒ¨: {e}")
                        continue
                
                if model is None:
                    logger.warning(" ì „ì´í•™ìŠµ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ìˆœìˆ˜ í•™ìŠµìœ¼ë¡œ ì§„í–‰")
                    model = SAC('MlpPolicy', env, **sac_config)
                    
            except ImportError:
                logger.warning(" huggingface_sb3 ì„¤ì¹˜ ì‹¤íŒ¨, ìˆœìˆ˜ í•™ìŠµìœ¼ë¡œ ì§„í–‰")
                model = SAC('MlpPolicy', env, **sac_config)
            except Exception as e:
                logger.warning(f" ì „ì´í•™ìŠµ ì‹¤íŒ¨: {e}, ìˆœìˆ˜ í•™ìŠµìœ¼ë¡œ ì§„í–‰")
                model = SAC('MlpPolicy', env, **sac_config)
        else:
            logger.warning(" ì „ì´í•™ìŠµ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì‹¤íŒ¨, ìˆœìˆ˜ í•™ìŠµìœ¼ë¡œ ì§„í–‰")
            model = SAC('MlpPolicy', env, **sac_config)
    else:
        logger.info("ğŸ†• ìˆœìˆ˜ í•™ìŠµ ëª¨ë¸ ìƒì„±")
        model = SAC('MlpPolicy', env, **sac_config)
    
    # ì½œë°± ì„¤ì • (SageMaker ìµœì í™”)
    eval_callback = PerformanceMetricsCallback(
        eval_env=env,
        eval_freq=2000,  # SageMakerìš© ë¹ˆë„ ì¡°ì •
        verbose=1
    )
    
    # í›ˆë ¨ ì‹œì‘
    logger.info(f" í•™ìŠµ ì‹œì‘ - ëª©í‘œ: {total_timesteps} ìŠ¤í…")
    start_time = datetime.now()
    
    try:
        model.learn(
            total_timesteps=total_timesteps,
            callback=eval_callback,
            log_interval=100,
            progress_bar=True
        )
        
        end_time = datetime.now()
        training_time = (end_time - start_time).total_seconds()
        logger.info(f" í•™ìŠµ ì™„ë£Œ! ì†Œìš”ì‹œê°„: {training_time:.1f}ì´ˆ")
        
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ì ì¤‘ë‹¨")
    except Exception as e:
        logger.error(f" í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None, None
    
    # ëª¨ë¸ ì €ì¥
    model_path = f"{save_dir}/{model_name}.zip"
    model.save(model_path)
    logger.info(f" ëª¨ë¸ ì €ì¥: {model_path}")
    
    # ì„±ëŠ¥ í‰ê°€ (ì‹¤í—˜ ì„¤ê³„ì„œ ê¸°ì¤€)
    logger.info("ìµœì¢… ì„±ëŠ¥ í‰ê°€ ì¤‘...")
    eval_results, eval_episodes = evaluate_policy(
        model, env, n_eval_episodes=50, return_episode_rewards=True  # 50íšŒë¡œ ì¦ê°€
    )
    
    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    final_metrics = []
    for _ in range(50):  # 50íšŒë¡œ ì¦ê°€
        obs, _ = env.reset()
        done = False
        while not done:
            action, _ = model.predict(obs, deterministic=True)
            obs, _, terminated, truncated, _ = env.step(action)
            done = terminated or truncated
        final_metrics.append(env.get_episode_metrics())
    
    # ê²°ê³¼ ì •ë¦¬
    results = {
        'model_name': model_name,
        'is_transfer_learning': is_transfer_learning,
        'training_time': training_time,
        'total_timesteps': total_timesteps,
        'eval_mean_reward': np.mean(eval_results),
        'eval_std_reward': np.std(eval_results),
        'metrics': {
            'energy_efficiency': {
                'mean': np.mean([m['energy_efficiency'] for m in final_metrics]),
                'std': np.std([m['energy_efficiency'] for m in final_metrics]),
                'values': [m['energy_efficiency'] for m in final_metrics]
            },
            'speed_tracking_rate': {
                'mean': np.mean([m['speed_tracking_rate'] for m in final_metrics]),
                'std': np.std([m['speed_tracking_rate'] for m in final_metrics]),
                'values': [m['speed_tracking_rate'] for m in final_metrics]
            },
            'soc_decrease_rate': {
                'mean': np.mean([m['soc_decrease_rate'] for m in final_metrics]),
                'std': np.std([m['soc_decrease_rate'] for m in final_metrics]),
                'values': [m['soc_decrease_rate'] for m in final_metrics]
            }
        },
        'learning_history': eval_callback.metrics_history
    }
    
    # ê²°ê³¼ ì €ì¥
    results_path = f"./results/{model_name}_results.json"
    with open(results_path, 'w') as f:
        # JSON ì§ë ¬í™”ë¥¼ ìœ„í•´ numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        json_results = {}
        for key, value in results.items():
            if isinstance(value, np.ndarray):
                json_results[key] = value.tolist()
            elif isinstance(value, dict):
                json_results[key] = {}
                for k, v in value.items():
                    if isinstance(v, dict):
                        json_results[key][k] = {}
                        for kk, vv in v.items():
                            if isinstance(vv, np.ndarray):
                                json_results[key][k][kk] = vv.tolist()
                            else:
                                json_results[key][k][kk] = vv
                    else:
                        json_results[key][k] = v
            else:
                json_results[key] = value
        
        json.dump(json_results, f, indent=2)
    
    logger.info(f"ê²°ê³¼ ì €ì¥: {results_path}")
    
    return model, results


def compare_models_and_baseline():
    """ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë° ë¶„ì„ - SageMaker ì„¤ì •"""
    
    logger.info("=" * 60)
    logger.info("SAC ì „ê¸°ì°¨ ì—ë„ˆì§€ íš¨ìœ¨ ìµœì í™” ì‹¤í—˜ ì‹œì‘ (SageMaker ìµœì í™”)")
    logger.info("=" * 60)
    
    # ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸
    data_dir = "./data"
    if not os.path.exists(data_dir):
        logger.error(f" ë°ì´í„° ë””ë ‰í† ë¦¬ ì—†ìŒ: {data_dir}")
        logger.info(" ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ìƒì„±í•˜ì„¸ìš”:")
        logger.info("  - ./data/rush_separated_train_corrected_*.csv")
        logger.info("  - ./data/rush_separated_test_corrected_*.csv")
        logger.info("  - ./data/rush_normalization_corrected_*.json")
        return
    
    # í™˜ê²½ ìƒì„± (ê¸°ì¤€ì„  í‰ê°€ìš©)
    env = EVEnergyEnvironmentPreprocessed(data_dir=data_dir)
    
    # 1. í¬ë£¨ì¦ˆ ëª¨ë“œ ê¸°ì¤€ì„  í‰ê°€
    logger.info("1ë‹¨ê³„: í¬ë£¨ì¦ˆ ëª¨ë“œ ê¸°ì¤€ì„  í‰ê°€")
    cruise_results, cruise_episodes = evaluate_cruise_baseline(env, num_episodes=50)
    
    logger.info("í¬ë£¨ì¦ˆ ëª¨ë“œ ê²°ê³¼:")
    logger.info(f"  ì—ë„ˆì§€ íš¨ìœ¨: {cruise_results['energy_efficiency']['mean']:.3f} km/kWh")
    logger.info(f"  ì†ë„ ì¶”ì¢…ë¥ : {cruise_results['speed_tracking_rate']['mean']:.1f}%")
    logger.info(f"  í‰ê·  ë³´ìƒ: {cruise_results['episode_reward']['mean']:.3f}")
    
    # 2. SAC ìˆœìˆ˜ í•™ìŠµ (ì‹¤í—˜ ì„¤ê³„ì„œ ê¸°ì¤€)
    logger.info("\n 2ë‹¨ê³„: SAC ìˆœìˆ˜ í•™ìŠµ")
    sac_scratch_model, sac_scratch_results = train_sac_model(
        model_name="sac_from_scratch",
        is_transfer_learning=False,
        total_timesteps=100000,  # ìˆœìˆ˜ í•™ìŠµìš© ìŠ¤í… ìˆ˜
        data_dir=data_dir
    )
    
    if sac_scratch_results:
        logger.info("SAC ìˆœìˆ˜ í•™ìŠµ ê²°ê³¼:")
        logger.info(f"  ì—ë„ˆì§€ íš¨ìœ¨: {sac_scratch_results['metrics']['energy_efficiency']['mean']:.3f} km/kWh")
        logger.info(f"  ì†ë„ ì¶”ì¢…ë¥ : {sac_scratch_results['metrics']['speed_tracking_rate']['mean']:.1f}%")
        logger.info(f"  í‰ê·  ë³´ìƒ: {sac_scratch_results['eval_mean_reward']:.3f}")
        logger.info(f"  í•™ìŠµ ì‹œê°„: {sac_scratch_results['training_time']:.1f}ì´ˆ")
    
    # 3. SAC ì „ì´ í•™ìŠµ (ì‹¤í—˜ ì„¤ê³„ì„œ ê¸°ì¤€)
    logger.info("\n 3ë‹¨ê³„: SAC ì „ì´ í•™ìŠµ")
    sac_transfer_model, sac_transfer_results = train_sac_model(
        model_name="sac_with_transfer",
        is_transfer_learning=True,
        total_timesteps=50000,  # ì „ì´ í•™ìŠµìš© ìŠ¤í… ìˆ˜ (50% ë‹¨ì¶•)
        data_dir=data_dir
    )
    
    if sac_transfer_results:
        logger.info("SAC ì „ì´ í•™ìŠµ ê²°ê³¼:")
        logger.info(f"  ì—ë„ˆì§€ íš¨ìœ¨: {sac_transfer_results['metrics']['energy_efficiency']['mean']:.3f} km/kWh")
        logger.info(f"  ì†ë„ ì¶”ì¢…ë¥ : {sac_transfer_results['metrics']['speed_tracking_rate']['mean']:.1f}%")
        logger.info(f"  í‰ê·  ë³´ìƒ: {sac_transfer_results['eval_mean_reward']:.3f}")
        logger.info(f"  í•™ìŠµ ì‹œê°„: {sac_transfer_results['training_time']:.1f}ì´ˆ")
    
    # 4. ê²°ê³¼ ë¹„êµ ë° ë¶„ì„
    logger.info("\n4ë‹¨ê³„: ê²°ê³¼ ë¹„êµ ë° ë¶„ì„")
    
    comparison_results = {
        'cruise_mode': cruise_results,
        'sac_scratch': sac_scratch_results,
        'sac_transfer': sac_transfer_results
    }
    
    # ì‹¤í—˜ ì„¤ê³„ì„œ ê¸°ì¤€ ë¹„êµ í‘œ ìƒì„±
    print("\n" + "="*80)
    print("ì„±ëŠ¥ ë¹„êµ ìš”ì•½ (ì‹¤í—˜ ì„¤ê³„ì„œ ê¸°ì¤€)")
    print("="*80)
    print(f"{'ëª¨ë¸':<20} {'ì—ë„ˆì§€íš¨ìœ¨':<12} {'ì†ë„ì¶”ì¢…ë¥ ':<12} {'í‰ê· ë³´ìƒ':<10} {'í•™ìŠµì‹œê°„':<10}")
    print("-"*80)
    
    # í¬ë£¨ì¦ˆ ëª¨ë“œ
    print(f"{'í¬ë£¨ì¦ˆ ëª¨ë“œ':<20} {cruise_results['energy_efficiency']['mean']:<12.3f} "
          f"{cruise_results['speed_tracking_rate']['mean']:<12.1f} "
          f"{cruise_results['episode_reward']['mean']:<10.3f} {'N/A':<10}")
    
    # SAC ìˆœìˆ˜ í•™ìŠµ
    if sac_scratch_results:
        print(f"{'SAC ìˆœìˆ˜í•™ìŠµ':<20} {sac_scratch_results['metrics']['energy_efficiency']['mean']:<12.3f} "
              f"{sac_scratch_results['metrics']['speed_tracking_rate']['mean']:<12.1f} "
              f"{sac_scratch_results['eval_mean_reward']:<10.3f} {sac_scratch_results['training_time']:<10.1f}")
    
    # SAC ì „ì´ í•™ìŠµ
    if sac_transfer_results:
        print(f"{'SAC ì „ì´í•™ìŠµ':<20} {sac_transfer_results['metrics']['energy_efficiency']['mean']:<12.3f} "
              f"{sac_transfer_results['metrics']['speed_tracking_rate']['mean']:<12.1f} "
              f"{sac_transfer_results['eval_mean_reward']:<10.3f} {sac_transfer_results['training_time']:<10.1f}")
    
    print("="*80)
    
    # ì‹¤í—˜ ì„¤ê³„ì„œ ê°€ì„¤ ê²€ì¦
    if sac_scratch_results and sac_transfer_results:
        cruise_efficiency = cruise_results['energy_efficiency']['mean']
        scratch_efficiency = sac_scratch_results['metrics']['energy_efficiency']['mean']
        transfer_efficiency = sac_transfer_results['metrics']['energy_efficiency']['mean']
        
        scratch_improvement = ((scratch_efficiency - cruise_efficiency) / cruise_efficiency) * 100
        transfer_improvement = ((transfer_efficiency - cruise_efficiency) / cruise_efficiency) * 100
        
        # ìˆ˜ë ´ ì‹œê°„ ë¹„êµ
        scratch_time = sac_scratch_results['training_time']
        transfer_time = sac_transfer_results['training_time']
        time_reduction = ((scratch_time - transfer_time) / scratch_time) * 100
        
        print(f"\n ì‹¤í—˜ ì„¤ê³„ì„œ ê°€ì„¤ ê²€ì¦:")
        print(f"  H1 - ì „ì´í•™ìŠµ > ìˆœìˆ˜í•™ìŠµ > í¬ë£¨ì¦ˆ: {' ì„±ê³µ' if transfer_efficiency > scratch_efficiency > cruise_efficiency else ' ì‹¤íŒ¨'}")
        print(f"  H2 - ì „ì´í•™ìŠµ ìˆ˜ë ´ ì‹œê°„ ë‹¨ì¶•: {time_reduction:+.1f}% ({' ì„±ê³µ' if time_reduction > 0 else ' ì‹¤íŒ¨'})")
        print(f"  H3 - 20% ì´ìƒ íš¨ìœ¨ ê°œì„ :")
        print(f"    ìˆœìˆ˜í•™ìŠµ: {scratch_improvement:+.1f}% ({' ë‹¬ì„±' if scratch_improvement >= 20 else ' ë¯¸ë‹¬'})")
        print(f"    ì „ì´í•™ìŠµ: {transfer_improvement:+.1f}% ({' ë‹¬ì„±' if transfer_improvement >= 20 else ' ë¯¸ë‹¬'})")
        
        if transfer_efficiency > scratch_efficiency:
            transfer_advantage = ((transfer_efficiency - scratch_efficiency) / scratch_efficiency) * 100
            print(f"  ì „ì´í•™ìŠµ ìš°ìœ„: {transfer_advantage:+.1f}%")
    
    # ìµœì¢… ê²°ê³¼ ì €ì¥
    final_comparison = {
        'experiment_date': datetime.now().isoformat(),
        'data_directory': data_dir,
        'sagemaker_optimized': True,
        'hypothesis_verification': {
            'H1_efficiency_ranking': transfer_efficiency > scratch_efficiency > cruise_efficiency if sac_scratch_results and sac_transfer_results else False,
            'H2_convergence_speedup': time_reduction > 0 if sac_scratch_results and sac_transfer_results else False,
            'H3_20percent_improvement': {
                'scratch_achieved': scratch_improvement >= 20 if sac_scratch_results else False,
                'transfer_achieved': transfer_improvement >= 20 if sac_transfer_results else False
            }
        },
        'results': comparison_results
    }
    
    with open('./results/final_comparison_sagemaker.json', 'w') as f:
        # JSON ì§ë ¬í™” ì²˜ë¦¬
        def serialize_for_json(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {k: serialize_for_json(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [serialize_for_json(item) for item in obj]
            else:
                return obj
        
        json.dump(serialize_for_json(final_comparison), f, indent=2)
    
    logger.info(" ìµœì¢… ë¹„êµ ê²°ê³¼ ì €ì¥: ./results/final_comparison_sagemaker.json")
    
    return comparison_results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - SageMaker ìµœì í™”"""
    parser = argparse.ArgumentParser(description='SAC ì „ê¸°ì°¨ ì—ë„ˆì§€ íš¨ìœ¨ ìµœì í™” - SageMaker ì‹¤í—˜')
    parser.add_argument('--data_dir', type=str, default='./data', 
                       help='ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--timesteps_scratch', type=int, default=100000,
                       help='ìˆœìˆ˜í•™ìŠµ ìŠ¤í… ìˆ˜ (ì‹¤í—˜ ì„¤ê³„ì„œ ê¸°ì¤€)')
    parser.add_argument('--timesteps_transfer', type=int, default=50000,
                       help='ì „ì´í•™ìŠµ ìŠ¤í… ìˆ˜ (ì‹¤í—˜ ì„¤ê³„ì„œ ê¸°ì¤€)')
    parser.add_argument('--mode', type=str, choices=['compare', 'train_scratch', 'train_transfer'], 
                       default='compare', help='ì‹¤í–‰ ëª¨ë“œ')
    parser.add_argument('--aws_instance', type=str, default='ml.m5.xlarge',
                       help='AWS SageMaker ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…')
    
    args = parser.parse_args()
    
    # SageMaker í™˜ê²½ ì •ë³´ ë¡œê¹…
    logger.info(" SageMaker ìµœì í™” SAC ì‹¤í—˜ ì‹œì‘")
    logger.info(f"ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…: {args.aws_instance}")
    logger.info(f"ë°ì´í„° ë””ë ‰í† ë¦¬: {args.data_dir}")
    logger.info(f"ì‹¤í–‰ ëª¨ë“œ: {args.mode}")
    
    if args.mode == 'compare':
        # ì „ì²´ ë¹„êµ ì‹¤í—˜ ì‹¤í–‰ (ì‹¤í—˜ ì„¤ê³„ì„œ ì „ì²´)
        results = compare_models_and_baseline()
        
    elif args.mode == 'train_scratch':
        # ìˆœìˆ˜ í•™ìŠµë§Œ ì‹¤í–‰
        model, results = train_sac_model(
            model_name="sac_from_scratch",
            is_transfer_learning=False,
            total_timesteps=args.timesteps_scratch,
            data_dir=args.data_dir
        )
        
    elif args.mode == 'train_transfer':
        # ì „ì´ í•™ìŠµë§Œ ì‹¤í–‰
        model, results = train_sac_model(
            model_name="sac_with_transfer", 
            is_transfer_learning=True,
            total_timesteps=args.timesteps_transfer,
            data_dir=args.data_dir
        )
    
    logger.info("SageMaker ì‹¤í—˜ ì™„ë£Œ")


if __name__ == "__main__":
    main()
